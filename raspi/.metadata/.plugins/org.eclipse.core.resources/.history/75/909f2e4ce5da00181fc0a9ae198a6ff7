package org.usfirst.frc.team4276.vision;

import java.util.ArrayList;

import edu.wpi.first.wpilibj.networktables.*;
import edu.wpi.cscore.*;
import org.opencv.core.Mat;
import org.opencv.core.MatOfPoint;
import org.opencv.core.Rect;
import org.opencv.core.Point;
import org.opencv.core.Scalar;
import org.opencv.imgproc.Imgproc;
import org.usfirst.frc.team4276.vision.GripPipeline;

public class Main {

	private final static Object imgLock = new Object();
	private static GripPipeline myGripPipeline = null;

	public static void main(String[] args) {
		// Loads our OpenCV library. This MUST be included
		System.out.println("project_loc = " + System.getProperty("project_loc")); 
		System.out.println("java.libary.path = " + System.getProperty("java.library.path")); 
		System.loadLibrary("opencv");
		
		myGripPipeline = new GripPipeline();

		// Connect NetworkTables, and get access to the publishing table
		NetworkTable.setClientMode();
		// Set your team number here
		NetworkTable.setTeam(4276);

		NetworkTable.initialize();

		// This is the network port you want to stream the raw received image to
		// By rules, this has to be between 1180 and 1190, so 1185 is a good choice
		int streamPort = 1185;

		// This stores our reference to our mjpeg server for streaming the input image
		MjpegServer inputStream = new MjpegServer("MJPEG Server", streamPort);

		// Selecting a Camera
		// Uncomment one of the 2 following camera options
		// The top one receives a stream from another device, and performs operations
		// based on that
		// On windows, this one must be used since USB is not supported
		// The bottom one opens a USB camera, and performs operations on that, along
		// with streaming
		// the input image so other devices can see it.

		// HTTP Camera
		/*
		 * // This is our camera name from the robot. this can be set in your robot code
		 * with the following command //
		 * CameraServer.getInstance().startAutomaticCapture("YourCameraNameHere"); //
		 * "USB Camera 0" is the default if no string is specified String cameraName =
		 * "USB Camera 0"; HttpCamera camera = setHttpCamera(cameraName, inputStream);
		 * // It is possible for the camera to be null. If it is, that means no camera
		 * could // be found using NetworkTables to connect to. Create an HttpCamera by
		 * giving a specified stream // Note if this happens, no restream will be
		 * created if (camera == null) { camera = new HttpCamera("CoprocessorCamera",
		 * "YourURLHere"); inputStream.setSource(camera); }
		 */

		/***********************************************/

		// USB Camera
		// This gets the image from a USB camera
		// Usually this will be on device 0, but there are other overloads
		// that can be used
		UsbCamera camera = setUsbCamera(0, inputStream);
		// Set the resolution for our camera, since this is over USB
		camera.setResolution(640, 480);

		// This creates a CvSink for us to use. This grabs images from our selected
		// camera,
		// and will allow us to use those images in opencv
		CvSink imageSink = new CvSink("CV Image Grabber");
		imageSink.setSource(camera);

		// This creates a CvSource to use. This will take in a Mat image that has had
		// OpenCV operations
		// operations
		CvSource imageSource = new CvSource("CV Image Source", VideoMode.PixelFormat.kMJPEG, 640, 480, 30);
		MjpegServer cvStream = new MjpegServer("CV Image Stream", 1186);
		cvStream.setSource(imageSource);

		// All Mats and Lists should be stored outside the loop to avoid allocations
		// as they are expensive to create
		Mat inputImage = new Mat();

		// Infinitely process image
		while (true) {
			// Grab a frame. If it has a frame time of 0, there was an error.
			// Just skip and continue
			long frameTime = imageSink.grabFrame(inputImage);
			if (frameTime == 0) {
				continue;
			}
			myGripPipeline.process(inputImage);
			ArrayList<MatOfPoint> contours = myGripPipeline.findContoursOutput();
			if (!contours.isEmpty()) {
				Rect rectLargest = Imgproc.boundingRect(contours.get(0));
				double centerX = rectLargest.x + (rectLargest.width / 2);
				double centerY = rectLargest.y + (rectLargest.height / 2);
				float radius = Math.min(rectLargest.width, rectLargest.height);
				Scalar colorBlue = new Scalar(0, 0, 255);
				synchronized (imgLock) {
					Point pt1 = new Point(centerX - radius, centerY);
					Point pt2 = new Point(centerX + radius, centerY);
					Imgproc.line(inputImage, pt1, pt2, colorBlue);
					Point pt3 = new Point(centerX, centerY - radius);
					Point pt4 = new Point(centerX, centerY + radius);
					Imgproc.line(inputImage, pt3, pt4, colorBlue);
				}
			}
			imageSource.putFrame(inputImage);
		}
	}

	/*
	 * private static HttpCamera setHttpCamera(String cameraName, MjpegServer
	 * server) { // Start by grabbing the camera from NetworkTables NetworkTable
	 * publishingTable = NetworkTable.getTable("CameraPublisher"); // Wait for robot
	 * to connect. Allow this to be attempted indefinitely while (true) { try { if
	 * (publishingTable.getSubTables().size() > 0) { break; } Thread.sleep(500); }
	 * catch (Exception e) { // TODO Auto-generated catch block e.printStackTrace();
	 * } }
	 * 
	 * HttpCamera camera = null; if (!publishingTable.containsSubTable(cameraName))
	 * { return null; } ITable cameraTable =
	 * publishingTable.getSubTable(cameraName); String[] urls =
	 * cameraTable.getStringArray("streams", null); if (urls == null) { return null;
	 * } ArrayList<String> fixedUrls = new ArrayList<String>(); for (String url :
	 * urls) { if (url.startsWith("mjpg")) { fixedUrls.add(url.split(":", 2)[1]); }
	 * } camera = new HttpCamera("CoprocessorCamera", fixedUrls.toArray(new
	 * String[0])); server.setSource(camera); return camera; }
	 */

	private static UsbCamera setUsbCamera(int cameraId, MjpegServer server) {
		// This gets the image from a USB camera
		// Usually this will be on device 0, but there are other overloads
		// that can be used
		UsbCamera camera = new UsbCamera("CoprocessorCamera", cameraId);
		server.setSource(camera);
		return camera;
	}
}